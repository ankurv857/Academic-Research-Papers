\section{Introduction}
Lately, neural network ensembles have been widely applied in the field machine learning. One of the reason being,
ensembles of neural networks are known to be much more robust and accurate than individual networks. However, 
training multiple deep networks as sumbodels and then averaging the predictions is computationally expensive.
In this paper we argue that weighted average of multiple local minima of a single network can be as effective,
and we acheive this by saving the model parameters of a single neural network at several local minima.