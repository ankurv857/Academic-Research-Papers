\section{Discussion}
\label{sec:disc}

In this section we discuss the limitations of our approach, including
attacks against our solution, and the impacts of the trade-offs made
during the implementation of \name and the network reconnaissance
attack simulation.

\subsection{Limitations}
We now focus on limitations of both the proposed network reconnaissance
attack and the proposed solution at a high level, including how the
assumptions of our threat model may impact real world applications in an
SDN.

% passive (core switch compromise)
% only one compromised (similar configure)
\myparagraph{Fully Passive Adversaries}
If an adversary controls a core switch in the network, he may monitor the
network policy by passively viewing the switch's flow table and does not
need to send reconnaissance packets. Thus \name cannot detect the
adversary in the network. We argue \name is part of a defense in depth
approach to network security, as it is not always guaranteed the
adversary will be able to compromise a core switch and may need to
launch an active reconnaissance attack. Similarly related, network
administrators often configure all switches in their network in the
same way and the same attack vectors may lead to compromise of more than
one switch. With this in mind, we still argue for the need for \name as
an adversary is not always guaranteed to compromise more than one switch
in a network.

% low network churn/vm migration
\myparagraph{VM Migration/Network Churn} \name is not implemented to
handle a high rate of network churn, i.e. virtual machine migration.
One of SDN's advantages is the ease in which VM's can be migrated
throughout the network, but in our current implementation we require the
network to have very little network churn. \name can be extended to
allow for VM migration, but it may have an adverse effect on network
overhead. This is left for future work.

% other security apps actually forward traffic to blackholes etc
\myparagraph{Attack Feasibility and Effectiveness} We have already
addressed the issue of a fully passive adversary. We also identify a 
situation where the attack does not effectively gather good 
intelligence of the network from the flow\_mod message. Since the 
adversary is only guessing the network policy based on the resulting 
flow\_mod messages, it is possible a forwarding decision may mislead an
adversary into believing a host can connect to the desired destination. 
For example, a security application may want all suspicious looking
connection attempts to divert into a honeynet or be forwarded to a 
blackhole that is more than one hop away. Since the adversary can only
determine connectivity based on the next hop the information gathered
from reconnaissance is effectively useless. If the blackhole or honeynet
is directly connected to the compromised switch it is possible for the
adversary to notice a difference in the expected output port and the
output port specified in the flow rule. From this information the
adversary can glean the position of middleboxes and other security
defenses.

% false positives (overwhelmed switch/race condition)
\myparagraph{False Positives} As seen in Section~\ref{sec:eval}, \name
successfully detected all attempted network reconnaissance with no false
positives. In order to generate false positives, we intentionally
introduced delays in \name's processing or lowered timeout intervals. We 
note this delay can happen naturally in a few situations. If a 
non-compromised switch is overwhelmed or experiencing 
networking/processing delays, it is possible for the information of a 
previous switch used by \name to expire before processing a packet\_in 
message associated with that information. When our app goes to access 
that information, it is not found and the non-compromised switch is 
falsely identified as compromised. Similarly, flows are installed on a 
switch for a short period of time, if a flow expires directly after 
being used to forward a packet then the next switch will be mislabeled
as malicious when its packet\_in message is verified. In the first 
case we argue the alarm could be used to identify a misconfiguration
in the network and the false positive can still provide useful 
information to network administrators. The race condition in the 
second case should be so rare, as we have not experienced during 
testing, that it will not cause too much of a hassle to inspect the 
offending packet manually.

% attack sending packet to other switch to make them seem compromised
\myparagraph{Attacks on \name} In addition to the false positives which
can occur accidentally, we have identified one attack on \name making it
appear another switch is compromised. Note this attack does not allow an
adversary to gather any intelligence about the network, but it may be
used to hide their compromised switch in a large number of alerts
generated by a non-compromised switch. According to our threat model the
adversary has full knowledge of our solution and maintains root access 
on the compromised switch. Considering these assumptions, an
adversary may launch an attack on neighboring switches to make them
raise alarms and be tagged as malicious. This is accomplished by an
adversary creating a packet and directly sending it out on a port
connected to another switch. When the target switch receives the packet
it generates a packet\_in message to be processed by \name. Since the
packet was received on a port connected to a switch, \name checks if the
compromised switch either flooded the packet or used a flow table rule;
however the packet was neither flooded or forwarded using flow table
rules so the targeted switch is falsely reported as compromised. At
worst, an adversary can only make neighboring switches generate false
alarms. If a large number of false alarms are generated an administrator
may still be alerted of potential malicious activity, but it is likely
an adversary can use this hide his reconnaissance activity in a flood of
false positives.

\subsection{Trade-offs}
% malicious app 
\myparagraph{Attack Implementation} In the interest of time, the attack
was simulated using a malicious app on the controller rather than fully
implementing malicious logic on the switch itself. The design of the
app carefully ensured it did not introduce any characteristic
differences making detection easier. The biggest effect introducing
the malicious app has on the evaluation is increased processing time
at the controller. Before a packet\_in message is processed by any
application it is first modified by the malicious app, causing a short
delay. Accounting for this, our baseline involved running the malicious
app; however we did not explore the overhead introduced by the malicious
app alone. 

% timeout threshold
\myparagraph{Timeout Thresholds} As mentioned in the limitations, we had
to artificially introduce false positives, although these race conditions
may happen naturally. The timeout thresholds, used by \name to determine 
if a packet\_in message with an event port connected to another switch
is spoofed, may increase the likelihood of a race condition happening if
they are set too low. In our experiments we did not see a performance
overhead nor an increase of false positives when varying the timeout
threshold. Future work may evaluate \name under an increased load of
packet\_in messages while varying the threshold timeouts to see how it
effects the network overhead and number of false positives. We note that
an overwhelming number of packet\_in events is very abnormal for a
network, and stress testing in this manner may not apply to realistic
environments.

% briefly mentioned in design
\myparagraph{Synchronous vs Asynchronous Processing} In its current
implementation \name processes packet\_in events asynchronously with
other applications running on the controller. This allows the adversary
to receive the flow\_mod message and gather intelligence about the
network. In a synchronous approach, \name would validate a packet\_in
message before other applications process the message. This has the
obvious drawback of increased overhead on latency and network
throughput, but prevents an adversary from gathering information using a
spoofed packet if \name drops the packet. If a prevention approach is
taken, the cost of false positives become much higher than in a
detection approach, although we note the conditions necessary to
produce a false positive rarely occur. In the event of a false positive,
the connection may be retried from the host, increasing the latency seen
by the two hosts. In the very unlikely case, the same connection would 
continuously encounter the race condition and lose its service in the 
network. Since detection satisfies our needs, we opted for just detection
and avoided unnecessary overhead.
